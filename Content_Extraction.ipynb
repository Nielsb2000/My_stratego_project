{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import regex as reg\n",
    "import joblib\n",
    "\n",
    "#import geopandas as gpd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset including ties and alternate stratego versions\n",
      "51333\n"
     ]
    }
   ],
   "source": [
    "directory = os.listdir('files/')\n",
    "print(\"total dataset including ties and alternate stratego versions\")\n",
    "print(len(directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of barrage(special version of Stratego) files, run code to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before barrage files removal\n",
      "51333\n",
      "number of barrage files removed\n",
      "0\n",
      "51333\n"
     ]
    }
   ],
   "source": [
    "num_barrage = 0\n",
    "directory = os.listdir('files/')\n",
    "print(\"before barrage files removal\")\n",
    "print(len(directory))\n",
    "for file in directory:\n",
    "    if file.endswith('.xml') and 'barrage' in file:\n",
    "        num_barrage += 1\n",
    "        os.remove(os.path.join('files/', file))\n",
    "print(\"number of barrage files removed\")\n",
    "print(num_barrage)\n",
    "directory = os.listdir('files/')\n",
    "print(len(directory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes the Freesetup files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before classic_free files removal\n",
      "51333\n",
      "number of classic_free files removed\n",
      "0\n",
      "51333\n"
     ]
    }
   ],
   "source": [
    "num_classic_free = 0\n",
    "directory = os.listdir('files/')\n",
    "print(\"before classic_free files removal\")\n",
    "print(len(directory))\n",
    "for file in directory:\n",
    "    if file.endswith('.xml') and 'classicfree' in file:\n",
    "        num_classic_free += 1\n",
    "        os.remove(os.path.join('files/', file))\n",
    "print(\"number of classic_free files removed\")\n",
    "print(num_classic_free)\n",
    "directory = os.listdir('files/')\n",
    "print(len(directory))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes the ultimate lightning files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before ultimate_lightning files removal\n",
      "51333\n",
      "number of ultimate_lightning files removed\n",
      "0\n",
      "51333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_ultimate_lightning = 0\n",
    "directory = os.listdir('files/')\n",
    "print(\"before ultimate_lightning files removal\")\n",
    "print(len(directory))\n",
    "for file in directory:\n",
    "    if file.endswith('.xml') and 'ultimate lightning' in file:\n",
    "        num_ultimate_lightning += 1\n",
    "        os.remove(os.path.join('files/', file))\n",
    "print(\"number of ultimate_lightning files removed\")\n",
    "print(num_ultimate_lightning)\n",
    "directory = os.listdir('files/')\n",
    "print(len(directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes the duell files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before duell files removal\n",
      "51333\n",
      "number of duell files removed\n",
      "0\n",
      "51333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classic_free = 0\n",
    "directory = os.listdir('files/')\n",
    "print(\"before duell files removal\")\n",
    "print(len(directory))\n",
    "for file in directory:\n",
    "    if file.endswith('.xml') and 'duell' in file:\n",
    "        num_classic_free += 1\n",
    "        os.remove(os.path.join('files/', file))\n",
    "print(\"number of duell files removed\")\n",
    "print(num_classic_free)\n",
    "directory = os.listdir('files/')\n",
    "print(len(directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ties are in the dataset, and removed from directory list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir('files/')\n",
    "\n",
    "total_tie = 0\n",
    "gsn_files = [file for file in directory if file.endswith('.gsn')]\n",
    "xml_files = [file for file in directory if file.endswith('.xml')]\n",
    "\n",
    "gsn_indexes = []\n",
    "xml_indexes = []\n",
    "\n",
    "for index, gsn_file in enumerate(gsn_files):\n",
    "    with open('files/' + str(gsn_file), 'r') as file:\n",
    "        gsn_data = file.read()\n",
    "        #print(gsn_file)\n",
    "    if int(gsn_data.split('\\n')[-2][-1]) == 2:\n",
    "        total_tie +=1\n",
    "        gsn_indexes.append(index)\n",
    "        file.close()\n",
    "\n",
    "for index, xml_file in enumerate(xml_files):\n",
    "    with open('files/' + str(xml_file), 'r') as file:\n",
    "        xml_data = file.read()\n",
    "    if int(xml_data.split()[-3].split('\"')[1]) == 3:\n",
    "        total_tie +=1\n",
    "        xml_indexes.append(index)\n",
    "        file.close()\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8615\n",
      "40952\n",
      "49567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsn_files = [file for index, file in enumerate(gsn_files) if index not in gsn_indexes]\n",
    "xml_files = [file for index, file in enumerate(xml_files) if index not in xml_indexes]\n",
    "print(len(gsn_files)),print(len(xml_files)), print(len(gsn_files)+len(xml_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len dataset\n",
      "51333\n",
      "dataset - ties\n",
      "49567\n",
      "proportion of ties\n",
      "0.03440282079753765\n",
      "total amount of ties\n",
      "1766\n"
     ]
    }
   ],
   "source": [
    "print('len dataset')\n",
    "print(len(os.listdir('files/')))\n",
    "print('dataset - ties')\n",
    "print(len(gsn_files)+len(xml_files))\n",
    "print('proportion of ties')\n",
    "print(1-(len(gsn_files)+len(xml_files))/(len(os.listdir('files/'))))\n",
    "print('total amount of ties')\n",
    "print(total_tie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of matches in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches in Strados\n",
      "49567\n",
      "Number of matches after getting both sides:\n",
      "99134\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of matches in Strados\")\n",
    "print(len(gsn_files)+len(xml_files))\n",
    "print(\"Number of matches after getting both sides:\")\n",
    "print((len(gsn_files)+len(xml_files))*2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that the code doesn't count the opponenets side correctly, so we have to flip the data such that it is encoded in an identical manner with the other side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N',\n",
       " 'R',\n",
       " 'Y',\n",
       " 'P',\n",
       " 'R',\n",
       " 'N',\n",
       " 'N',\n",
       " 'R',\n",
       " 'N',\n",
       " 'N',\n",
       " 'S',\n",
       " 'P',\n",
       " 'R',\n",
       " 'Q',\n",
       " 'T',\n",
       " 'Q',\n",
       " 'U',\n",
       " 'Q',\n",
       " 'P',\n",
       " 'T',\n",
       " 'Q',\n",
       " 'S',\n",
       " 'P',\n",
       " 'P',\n",
       " 'S',\n",
       " 'X',\n",
       " 'P',\n",
       " 'V',\n",
       " 'S',\n",
       " 'Q',\n",
       " 'W',\n",
       " 'U',\n",
       " 'O',\n",
       " 'V',\n",
       " 'T',\n",
       " 'U',\n",
       " 'P',\n",
       " 'N',\n",
       " 'P',\n",
       " 'T']"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_string_op_side = xml_data.split()[7].split('\"')[1][60:100]\n",
    "\n",
    "#[::-1] This flips the perspective of the board such that right hand side stays right hand side\n",
    "\n",
    "last_row = list(og_string_op_side)[0:10][::-1] #is encoded as currently first\n",
    "thrd_row = list(og_string_op_side)[10:20][::-1] #is encoded as currently 2nd \n",
    "scnd_row = list(og_string_op_side)[20:30][::-1] #is encoded as currently 3rd\n",
    "first_row =list(og_string_op_side)[30:40][::-1] #is encoded as currently 4th\n",
    "\n",
    "flipped_string_op_side = list(first_row + scnd_row + thrd_row + last_row)\n",
    "flipped_string_op_side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract GSN data and puts it in 2 arrays; 1 for wins and 1 for positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_list_gsn = np.array([])\n",
    "all_encoded_data_1 = np.array([])\n",
    "all_encoded_data_2 = np.array([])\n",
    "gsn_game_dataframe = pd.DataFrame()\n",
    "all_encoded_data_gsn = np.array([])\n",
    "both_player_encoded_data = np.array([])\n",
    "player_list_1_gsn = []\n",
    "player_list_2_gsn = []\n",
    "total_pos_list_gsn = list()\n",
    "notation_list = []\n",
    "type_list = []\n",
    "\n",
    "\n",
    "for idx, gsn_file in enumerate(gsn_files):\n",
    "    with open('files/' + str(gsn_file), 'r') as file:\n",
    "        gsn_data = file.read()\n",
    "        notation_list.append(gsn_data.split('\\n')[0]) #notation\n",
    "        type_list.append(gsn_data.split('\\n')[1]) #type \n",
    "    if int(gsn_data.split('\\n')[-2][-1]) < 0 and int(gsn_data.split('\\n')[-2][-1]) > 1:\n",
    "        continue\n",
    "    else:\n",
    "        if int(gsn_data.split('\\n')[-2][-1]) == 2: #check if it is not a tie\n",
    "            #total matches including ties was 85292 without its 82216\n",
    "            continue\n",
    "        #elif int(xml_data.split()[-3].split('\"')[1]) == 1:\n",
    "        #    continue\n",
    "        else:\n",
    "            player_1_side_str = gsn_data.split('\\n')[2][0:40]\n",
    "            ##split the starting positions per player\n",
    "            player_2_side_str = gsn_data.split('\\n')[2][60:100]\n",
    "            \n",
    "            #This flips the perspective of the board such that right hand side stays right hand side\n",
    "            last_row = list(player_2_side_str)[0:10][::-1] #is encoded as currently first\n",
    "            thrd_row = list(player_2_side_str)[10:20][::-1] #is encoded as currently 2nd \n",
    "            scnd_row = list(player_2_side_str)[20:30][::-1] #is encoded as currently 3rd\n",
    "            first_row =list(player_2_side_str)[30:40][::-1] #is encoded as currently 4th\n",
    "\n",
    "            flipped_string_op_side = list(first_row + scnd_row + thrd_row + last_row)\n",
    "            \n",
    "            player_1_side = np.array(list(player_1_side_str)) \n",
    "            player_2_side = np.array(list(flipped_string_op_side))#creates arrays for encoding the starting positions\n",
    "            #print(gsn_file)\n",
    "\n",
    "            unique_pieces_1 = np.unique(player_1_side)\n",
    "            unique_pieces_2 = np.unique(player_2_side)\n",
    "            #creates an identity matrix with shape (number of letters, number of letters)\n",
    "            identity_matrix = np.eye(len(unique_pieces_1))\n",
    "            identity_matrix = np.eye(len(unique_pieces_2))\n",
    "            #maps letter values to dummy variables\n",
    "            dummy_variables_1 = identity_matrix[np.searchsorted(unique_pieces_1, player_1_side)]\n",
    "            dummy_variables_2 = identity_matrix[np.searchsorted(unique_pieces_2, player_2_side)]\n",
    "\n",
    "\n",
    "            player_list_1_gsn.append(dummy_variables_1)\n",
    "            player_list_2_gsn.append(dummy_variables_2)\n",
    "            winner_list_gsn = np.append(winner_list_gsn, int(gsn_data.split('\\n')[-2][-1])) #creates a list of who won which game 1 indicates player 2 and 0 is the red player(player 1)\n",
    "\n",
    "player_list_1_gsn.extend(player_list_2_gsn)#creates a total list with the first players position being the first players'(red) arrays\n",
    "inverted_winner_list = 1 - winner_list_gsn\n",
    "both_sided_winner_list_gsn = np.append(inverted_winner_list, winner_list_gsn) # creates double the size of the winner list # doubles the size of the winner list by inverting the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17230, 17230, (40, 12))"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_sided_winner_list_gsn),len(player_list_1_gsn), dummy_variables_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40952"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xml_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract XML data and puts it in 2 arrays; 1 for wins and 1 for positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic-2014.9-2525.xml\n"
     ]
    }
   ],
   "source": [
    "winner_list_xml = np.array([])\n",
    "all_encoded_data_1 = np.array([])\n",
    "all_encoded_data_2 = np.array([])\n",
    "xml_game_dataframe = pd.DataFrame()\n",
    "all_encoded_data_xml = np.array([])\n",
    "both_player_encoded_data = np.array([])\n",
    "player_list_1_xml = []\n",
    "player_list_2_xml = []\n",
    "num_invalid = 0\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    with open('files/' + str(xml_file), 'r') as file:\n",
    "        xml_data = file.read()\n",
    "\n",
    "    if int(xml_data.split()[-3].split('\"')[1]) == 3: #check if it is not a tie\n",
    "        #total matches including ties was 85292 without its 82216\n",
    "        continue\n",
    "    if len(xml_data.split()[7].split('\"')[1][0:40])!=40: #check if it is not an invalid match(does not contain deployment information)\n",
    "        num_invalid += 1\n",
    "        print(xml_file) #exactly 1 file has no deployment for some reason?\n",
    "        continue\n",
    "    else:\n",
    "\n",
    "\n",
    "        #print(xml_file)\n",
    "        player_1_side_str = xml_data.split()[7].split('\"')[1][0:40]\n",
    "        ##split the starting positions per player\n",
    "        player_2_side_str = xml_data.split()[7].split('\"')[1][60:100]\n",
    "        \n",
    "        last_row = list(player_2_side_str)[0:10][::-1] #is encoded as currently first\n",
    "        thrd_row = list(player_2_side_str)[10:20][::-1] #is encoded as currently 2nd \n",
    "        scnd_row = list(player_2_side_str)[20:30][::-1] #is encoded as currently 3rd\n",
    "        first_row =list(player_2_side_str)[30:40][::-1] #is encoded as currently 4th\n",
    "\n",
    "        flipped_string_op_side = list(first_row + scnd_row + thrd_row + last_row)\n",
    "        \n",
    "        player_1_side = np.array(list(player_1_side_str)) \n",
    "        player_2_side = np.array(list(flipped_string_op_side))#creates arrays for encoding the starting positions\n",
    "\n",
    "        unique_pieces_1 = np.unique(player_1_side)\n",
    "        unique_pieces_2 = np.unique(player_2_side)\n",
    "        # Create an identity matrix with shape (number of letters, number of letters)\n",
    "        identity_matrix = np.eye(len(unique_pieces_1))\n",
    "        identity_matrix = np.eye(len(unique_pieces_2))\n",
    "        # Map letter values to dummy variables\n",
    "        dummy_variables_1 = identity_matrix[np.searchsorted(unique_pieces_1, player_1_side)]\n",
    "        dummy_variables_2 = identity_matrix[np.searchsorted(unique_pieces_2, player_2_side)]\n",
    "        dummy_variables_2 = dummy_variables_2[::-1]#Reverse the positional data for player 2\n",
    "\n",
    "        player_list_1_xml.append(dummy_variables_1)\n",
    "        player_list_2_xml.append(dummy_variables_2)\n",
    "\n",
    "\n",
    "        #encoder = LabelEncoder()\n",
    "        #encoded_data_1 = encoder.fit_transform(list(player_1_side)) #create dummy variables out of letters\n",
    "        #encoded_data_2 = encoder.fit_transform(list(player_2_side))\n",
    "        #if len(all_encoded_data_1) == 0:\n",
    "        #    all_encoded_data_1 = encoded_data_1\n",
    "        #    all_encoded_data_2 = encoded_data_2\n",
    "        #else: \n",
    "        #    all_encoded_data_1 = np.vstack((all_encoded_data_1, encoded_data_1)) #add encoding to long array of all encoding for all games\n",
    "        #    all_encoded_data_2 = np.vstack((all_encoded_data_2, encoded_data_2))\n",
    "        \n",
    "        winner_list_xml = np.append(winner_list_xml, int(xml_data.split()[-3].split('\"')[1])) #creates a list of who won which game 1 indicates player 2 and 0 is the red player(player 1)\n",
    "\n",
    "player_list_1_xml.extend(player_list_2_xml)#creates a total list with the first players position being the first 9021 arrays\n",
    "player_list_1_xml.extend(player_list_1_gsn)#combines all player positions from both file types\n",
    "i=-1\n",
    "for num in winner_list_xml:\n",
    "    i+=1\n",
    "    if num ==  2: ##means player 1 lost we change it to 0\n",
    "        winner_list_xml[i] = 0    \n",
    "inverted_winner_list_xml = 1 - winner_list_xml\n",
    "both_sided_winner_list_xml = np.append(winner_list_xml, inverted_winner_list_xml) # creates double the size of the winner list # doubles the size of the winner list by inverting the list\n",
    "all_winner_list = np.concatenate((both_sided_winner_list_xml, both_sided_winner_list_gsn))\n",
    "all_winner_list = list(all_winner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0\n",
      "95370  5.0\n",
      "         0\n",
      "86755 -4.0\n"
     ]
    }
   ],
   "source": [
    "bob = pd.DataFrame(all_winner_list)\n",
    "print(bob[bob[0]==5])\n",
    "bob = pd.DataFrame(all_winner_list)\n",
    "print(bob[bob[0]==-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for some reason there is a target value eg the result of the match with a -4,\n",
    "## Honestly I have no idea what this is so I'll just remove it, it messes with the visualizations in the statistical analysis part\n",
    "index_to_remove = 86755\n",
    "\n",
    "player_list_1_xml.pop(index_to_remove)\n",
    "all_winner_list.pop(index_to_remove)\n",
    "\n",
    "\n",
    "## for some reason there is a target value eg the result of the match with a 5,\n",
    "## Honestly I have no idea what this is so I'll just remove it, it messes with the visualizations in the statistical analysis part\n",
    "index_to_remove = 95369\n",
    "\n",
    "player_list_1_xml.pop(index_to_remove)\n",
    "all_winner_list.pop(index_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at matches we can find the index of the matches accordingly;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string 'classic.2003.05.06.357.gsn' is found at index 24.\n"
     ]
    }
   ],
   "source": [
    "#gsn_files[0]\n",
    "\n",
    "search_string = \"classic.2003.05.06.357.gsn\"\n",
    "\n",
    "# Find the index of the string\n",
    "try:\n",
    "    index = gsn_files.index(search_string)\n",
    "    print(f\"The string '{search_string}' is found at index {index}.\")\n",
    "except ValueError:\n",
    "    print(f\"The string '{search_string}' is not in the list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99130, 99130)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_list_1_xml), len(all_winner_list) #total length of xml data collected with the 1st array being independent and the 2nd dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17230\n",
      "81900\n"
     ]
    }
   ],
   "source": [
    "print(len(player_list_1_gsn)) \n",
    "print(len(player_list_1_xml)-len(player_list_1_gsn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code changes the input data, I tried to make something which might resemble the data or involve more complex calculations, but doesn't work as well as I thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this changes the 1 hot encoding to include the value of the row the piece is on\n",
    "    #the value is as such, a piece on row 1 has a value of -20 and the top has a value of 20\n",
    "\n",
    " #   idx = -1\n",
    " #   base_value = -0.5 * len(player_list_1_xml[0])\n",
    " #   for deployment in player_list_1_xml:\n",
    " #       idx +=1\n",
    " #       for row_index in range(deployment.shape[0]):\n",
    " #           row_value = base_value + row_index\n",
    " #           if row_value >= 0:\n",
    " #               row_value += 1\n",
    " #           for col_index in range(deployment.shape[1]):\n",
    " #               if player_list_1_xml[idx][row_index, col_index] == 1:\n",
    " #                   player_list_1_xml[idx][row_index, col_index] = row_value\n",
    "\n",
    " #   print(player_list_1_xml[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx= -1\n",
    "#for deployment in player_list_1_xml:\n",
    "#    idx+=1\n",
    "#    non_zero_elements = player_list_1_xml[idx][player_list_1_xml[idx] != 0]\n",
    "\n",
    "    # Normalize to [-1, 1]\n",
    "#    normalized_non_zero_elements = 2 * (non_zero_elements - np.min(non_zero_elements)) / (np.max(non_zero_elements) - np.min(non_zero_elements)) - 1\n",
    "\n",
    " #   normalized_array = np.copy(player_list_1_xml[idx])\n",
    "\n",
    "    # Replace non-zero elements with their normalized values\n",
    "  #  normalized_array[player_list_1_xml[idx] != 0] = normalized_non_zero_elements\n",
    "   # player_list_1_xml[idx] = normalized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_list_1_xml[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes the data to a csv file and combines the GSN and XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_encoded_positions.txt']"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savetxt(\"Y_winners_encoded.csv\", all_winner_list, delimiter=\",\")\n",
    "joblib.dump(player_list_1_xml, \"X_encoded_positions.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99130"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joblib.load(\"X_encoded_positions.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
